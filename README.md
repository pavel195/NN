# Сиамские нейронные сети для распознавания лиц

Курсовая работа по теме "Сиамские нейронные сети и задача распознавания лиц".

**Авторы**: Чипкинеев П., Рождествин Ф.  
**Руководитель**: Н. С. Мартыненко

## Описание

Реализация сиамской нейронной сети на основе ResNet-50 для задачи верификации лиц на датасете LFW (Labeled Faces in the Wild). Модель обучается с использованием контрастивной функции потерь и достигает accuracy 94.6% на тестовом множестве.

### Ключевые особенности

- **Сиамская архитектура**: Две идентичные ветви с общими весами для обучения метрики сходства
- **Предобученный backbone**: ResNet-50, предобученная на ImageNet
- **Контрастивная потеря**: Обучение метрики сходства вместо прямой классификации
- **Корректное разделение данных**: Разбиение на уровне людей для объективной оценки
- **Воспроизводимость**: Все случайные состояния зафиксированы

## Структура проекта

```
.
├── data/                           # Модуль для работы с данными
│   ├── __init__.py
│   ├── dataset.py                 # Класс LFWDataset для загрузки и обработки
│   └── lfw/                        # Директория с датасетом LFW
│       └── lfw-deepfunneled/
│           └── lfw-deepfunneled/
│               └── [имя_человека]/
│                   └── [изображения].jpg
├── model/                          # Реализация модели
│   ├── __init__.py
│   └── siamese_network.py         # Классы SiameseNetwork и ContrastiveLoss
├── checkpoint/                     # Директория для сохранения моделей
│   ├── best_model.pth             # Лучшая модель по валидационной потере
│   ├── final_model.pth            # Финальная модель после всех эпох
│   ├── training_curves.png        # График кривых обучения
│   └── test_results.txt           # Результаты на тестовом множестве
├── train.py                       # Скрипт обучения модели
├── eval.py                        # Скрипт оценки модели
├── test_setup.py                  # Скрипт для проверки работоспособности
├── test_train.py                  # Скрипт для быстрого теста обучения
├── requirements.txt               # Зависимости проекта
├── README.md                      # Этот файл
└── .gitignore                     # Исключения для git
```

## Установка

### 1. Клонирование репозитория

```bash
git clone <repository_url>
cd nn
```

### 2. Создание виртуального окружения

**На Linux/macOS:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**На Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3. Установка зависимостей

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Зависимости:**
- PyTorch >= 2.0.0
- torchvision >= 0.15.0
- numpy >= 1.24.0
- scikit-learn >= 1.3.0
- Pillow >= 10.0.0
- matplotlib >= 3.7.0

### 4. Подготовка данных

Скачайте датасет LFW с официального сайта: http://vis-www.cs.umass.edu/lfw/

Распакуйте архив в директорию `data/lfw/`. Структура должна быть следующей:
```
data/lfw/lfw-deepfunneled/lfw-deepfunneled/
├── Aaron_Eckhart/
│   └── Aaron_Eckhart_0001.jpg
├── Aaron_Guiel/
│   └── Aaron_Guiel_0001.jpg
└── ...
```

## Использование

### Проверка работоспособности

Перед полным обучением рекомендуется запустить тестовые скрипты:

```bash
# Проверка загрузки данных и создания модели
python test_setup.py

# Быстрый тест обучения на небольшом подмножестве
python test_train.py
```

Ожидаемый вывод:
- ✓ Все тесты пройдены! Код готов к использованию.
- ✓ Тест обучения пройден успешно!

### Обучение модели

**Базовое обучение:**
```bash
python train.py
```

**С параметрами:**
```bash
python train.py \
    --data_dir data/lfw/lfw-deepfunneled/lfw-deepfunneled \
    --batch_size 32 \
    --epochs 50 \
    --lr 0.001 \
    --embedding_dim 128 \
    --margin 1.0 \
    --checkpoint_dir checkpoint
```

**Параметры:**
- `--data_dir`: путь к директории с датасетом LFW (по умолчанию `data/lfw/lfw-deepfunneled/lfw-deepfunneled`)
- `--batch_size`: размер батча (по умолчанию 32)
- `--epochs`: количество эпох обучения (по умолчанию 50)
- `--lr`: начальный learning rate (по умолчанию 0.001)
- `--embedding_dim`: размерность эмбеддинга (по умолчанию 128)
- `--margin`: маржин для контрастивной потери (по умолчанию 1.0)
- `--checkpoint_dir`: директория для сохранения чекпойнтов (по умолчанию `checkpoint`)

**Что происходит во время обучения:**
1. Загрузка и разделение датасета на train/val/test (70%/15%/15%)
2. Генерация пар изображений для обучения
3. Обучение модели с сохранением лучшей версии
4. Построение графика кривых обучения

**Результаты обучения:**
- `checkpoint/best_model.pth` - лучшая модель по валидационной потере
- `checkpoint/final_model.pth` - финальная модель после всех эпох
- `checkpoint/training_curves.png` - график кривых обучения

### Оценка модели

**Базовая оценка:**
```bash
python eval.py
```

**С указанием чекпойнта:**
```bash
python eval.py \
    --checkpoint checkpoint/best_model.pth \
    --data_dir data/lfw/lfw-deepfunneled/lfw-deepfunneled \
    --batch_size 32
```

**Параметры:**
- `--checkpoint`: путь к чекпойнту модели (по умолчанию `checkpoint/best_model.pth`)
- `--data_dir`: путь к директории с датасетом LFW
- `--batch_size`: размер батча (по умолчанию 32)
- `--embedding_dim`: размерность эмбеддинга (по умолчанию 128)
- `--threshold`: порог для классификации (если не указан, будет найден оптимальный на валидации)

**Результаты оценки:**
Скрипт выводит метрики Accuracy, Precision, Recall и F1-score на тестовом множестве и сохраняет их в `checkpoint/test_results.txt`.

**Пример вывода:**
```
==================================================
РЕЗУЛЬТАТЫ НА ТЕСТОВОМ МНОЖЕСТВЕ
==================================================
Accuracy:  0.9460
Precision: 0.9390
Recall:    0.9520
F1-score:  0.9450
==================================================
```

## Архитектура модели

### Сиамская сеть

Модель состоит из двух идентичных ветвей на основе ResNet-50:
- **Backbone**: ResNet-50, предобученная на ImageNet (до слоя avgpool)
- **Projection head**: Двухслойный fully connected слой (2048 → 512 → 128)
- **L2 нормализация**: Эмбеддинги нормализуются для стабильности обучения

### Контрастивная потеря

$$L = (1-Y) \cdot D^2 + Y \cdot \max(0, m-D)^2$$

где:
- $Y$ — метка (0 если одно лицо, 1 если разные)
- $D$ — евклидово расстояние между эмбеддингами
- $m$ — маржин (1.0)

## Результаты

После обучения на полном датасете LFW модель достигает следующих результатов:

| Метрика | Значение |
|---------|----------|
| Accuracy | 0.946 |
| Precision | 0.939 |
| Recall | 0.952 |
| F1-score | 0.945 |

Модель значительно превосходит baseline подход (accuracy 0.870).

## Воспроизводимость

Все случайные состояния зафиксированы для обеспечения воспроизводимости результатов:
- `torch.manual_seed(42)`
- `np.random.seed(42)`
- `random.seed(42)`
- `torch.backends.cudnn.deterministic = True`
- `torch.backends.cudnn.benchmark = False`

Для воспроизведения результатов достаточно запустить `python train.py` с установленными зависимостями и тем же датасетом.

## Лицензия

Этот проект создан в рамках курсовой работы и предназначен для образовательных целей.

